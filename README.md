# ComparaÃ§Ã£o de Algoritmos de OrdenaÃ§Ã£o

Este projeto implementa vÃ¡rios algoritmos de ordenaÃ§Ã£o e analisa seu desempenho em diferentes tipos de listas, utilizando o padrÃ£o de design **Strategy** para modularizar a implementaÃ§Ã£o e **OpenTelemetry** para monitoramento e anÃ¡lise de logs. O objetivo Ã© comparar a eficiÃªncia dos algoritmos e entender seu impacto em listas de diferentes caracterÃ­sticas e tamanhos.

## Objetivo

O objetivo deste projeto Ã© comparar a eficiÃªncia dos seguintes algoritmos de ordenaÃ§Ã£o:

- **QuickSort**
- **MergeSort**
- **BubbleSort**
- **BubbleSort Otimizado**
- **InsertionSort**
- **SelectionSort**
- **HeapSort**
- **TimSort**
- **CountingSort**
- **RadixSort**
- **ShellSort**

Os testes sÃ£o executados em diferentes cenÃ¡rios para analisar tempo de execuÃ§Ã£o, nÃºmero de comparaÃ§Ãµes e trocas. As listas testadas variam em tamanho e tipo (aleatÃ³rias, ordenadas, reversas e com duplicados).
---

## Estrutura do Projeto

```
ğŸ“‚ Desafio-2
â”‚â”€â”€ ğŸ“„ main.py               # Executa os testes e gera grÃ¡ficos
â”‚â”€â”€ ğŸ“„ sorting_algorithms.py # ImplementaÃ§Ã£o dos algoritmos
â”‚â”€â”€ ğŸ“„ performance_tests.py  # Mede o tempo de execuÃ§Ã£o
â”‚â”€â”€ ğŸ“„ utils.py              # GeraÃ§Ã£o de listas de teste
â”‚â”€â”€ ğŸ“„ grafico.py            # GeraÃ§Ã£o de grÃ¡ficos
â”‚â”€â”€ ğŸ“„ README.md             # DocumentaÃ§Ã£o do projeto
```

---

## Como Executar

### **1ï¸âƒ£ Instalar DependÃªncias**
Verifique de ter o Python instalado e instale a biblioteca necessÃ¡ria:

```bash
pip install -r requirements.txt
```

### **2ï¸âƒ£ Executar os Testes**
Para rodar os testes de desempenho e gerar grÃ¡ficos:

```bash
python main.py
```

Isso executara testes para listas de diferentes tamanhos e caracterÃ­sticas.

---

## AnÃ¡lise de Complexidade

A tabela abaixo mostra a complexidade de tempo e espaÃ§o dos algoritmos de ordenaÃ§Ã£o analisados. As complexidades sÃ£o apresentadas para o melhor caso, caso mÃ©dio e pior caso, alÃ©m do uso de espaÃ§o auxiliar.

| Algoritmo        | Melhor Caso     | Caso MÃ©dio     | Pior Caso      | EspaÃ§o Auxiliar  |
|------------------|-----------------|----------------|----------------|------------------|
| **QuickSort**     | O(n log n)      | O(n log n)     | O(nÂ²)          | O(log n) (recursÃ£o) |
| **MergeSort**     | O(n log n)      | O(n log n)     | O(n log n)     | O(n) (cÃ³pia das listas) |
| **BubbleSort**    | O(n)            | O(nÂ²)          | O(nÂ²)          | O(1)             |
| **BubbleSort Optimized** | O(n)     | O(nÂ²)          | O(nÂ²)          | O(1)             |
| **InsertionSort** | O(n)            | O(nÂ²)          | O(nÂ²)          | O(1)             |
| **SelectionSort** | O(nÂ²)           | O(nÂ²)          | O(nÂ²)          | O(1)             |
| **HeapSort**      | O(n log n)      | O(n log n)     | O(n log n)     | O(1)             |
| **TimSort**       | O(n log n)      | O(n log n)     | O(n log n)     | O(n) (auxÃ­lio na mesclagem) |
| **CountingSort**  | O(n + k)        | O(n + k)       | O(n + k)       | O(k)             |
| **RadixSort**     | O(nk)           | O(nk)          | O(nk)          | O(n + k)         |
| **ShellSort**     | O(n log n)      | O(n^(3/2))     | O(nÂ²)          | O(1)             |

---

## InterpretaÃ§Ã£o dos Resultados

- **QuickSort**: Geralmente Ã© o algoritmo mais rÃ¡pido para listas grandes. No entanto, seu desempenho pode ser prejudicado em casos de listas **quase ordenadas** ou **jÃ¡ ordenadas**, pois o pior caso ocorre quando o pivÃ´ Ã© mal escolhido, resultando em \(O(n^2)\). Uma estratÃ©gia para evitar esse problema Ã© a escolha de um pivÃ´ aleatÃ³rio.
  
- **MergeSort**: Possui um desempenho estÃ¡vel independentemente da ordenaÃ§Ã£o da lista, com uma complexidade de tempo de \(O(n \log n)\) tanto no melhor quanto no pior caso. No entanto, seu uso de memÃ³ria Ã© maior, devido Ã  necessidade de alocar espaÃ§o auxiliar para as listas durante a fusÃ£o.
  
- **BubbleSort**: Embora seja simples de implementar, **BubbleSort** tem um desempenho muito ruim para listas grandes, com complexidade de \(O(n^2)\) tanto no melhor quanto no pior caso. Ã‰ mais adequado para listas pequenas ou como um algoritmo educativo.
  
- **BubbleSort Otimizado**: A versÃ£o otimizada do **BubbleSort** melhora o desempenho ao evitar passagens desnecessÃ¡rias, mas ainda Ã© \(O(n^2)\) no pior caso. Sua principal melhoria estÃ¡ em detectar se a lista jÃ¡ estÃ¡ ordenada antes de fazer mais passagens.

- **InsertionSort**: **InsertionSort** Ã© eficiente para listas pequenas e jÃ¡ ordenadas, com complexidade de \(O(n)\) no melhor caso. PorÃ©m, sua performance decai para \(O(n^2)\) em listas desordenadas.

- **SelectionSort**: Embora simples, **SelectionSort** tem uma complexidade de \(O(n^2)\) em todos os casos e nÃ£o oferece grandes vantagens sobre outros algoritmos mais eficientes, sendo adequado apenas para listas pequenas.

- **HeapSort**: **HeapSort** tem uma complexidade de \(O(n \log n)\) no melhor, mÃ©dio e pior caso, e oferece um desempenho relativamente estÃ¡vel em relaÃ§Ã£o aos outros algoritmos.

- **TimSort**: Este algoritmo, usado no Python, Ã© altamente otimizado para listas parcialmente ordenadas e combina as caracterÃ­sticas de **MergeSort** e **InsertionSort**. Seu desempenho Ã© sempre \(O(n \log n)\), mas com melhorias para listas reais.

- **CountingSort**: **CountingSort** Ã© um algoritmo linear (\(O(n + k)\)), mas depende do intervalo de valores dos dados (k). Ele Ã© ideal para listas com nÃºmeros inteiros em um intervalo pequeno.

- **RadixSort**: Embora sua complexidade seja \(O(nk)\), **RadixSort** pode ser eficiente quando o nÃºmero de dÃ­gitos (k) for pequeno, como em listas com nÃºmeros inteiros de tamanho fixo.

- **ShellSort**: **ShellSort** melhora a performance do **InsertionSort** ao realizar comparaÃ§Ãµes em intervalos maiores, mas sua complexidade ainda pode atingir \(O(n^2)\) em alguns casos.

---

## ConclusÃ£o

Este projeto demonstrou que a escolha do algoritmo de ordenaÃ§Ã£o pode **impactar drasticamente** o desempenho de uma aplicaÃ§Ã£o, dependendo das caracterÃ­sticas dos dados a serem ordenados.

- **QuickSort** Ã© tipicamente o mais eficiente para listas grandes e aleatÃ³rias, mas pode falhar em listas **quase ordenadas** ou **muito desordenadas**. A escolha de um pivÃ´ aleatÃ³rio pode melhorar seu desempenho.
- **MergeSort** oferece uma abordagem mais estÃ¡vel, com complexidade garantida de \(O(n \log n)\), mas usa mais memÃ³ria, o que pode ser um fator limitante.
- **BubbleSort** e **SelectionSort** devem ser evitados em listas grandes devido Ã  sua ineficiÃªncia.
- **TimSort** Ã© extremamente eficiente em listas parcialmente ordenadas, sendo uma excelente escolha quando o desempenho Ã© crucial e os dados tÃªm padrÃµes especÃ­ficos.
  
Em geral, a escolha do algoritmo deve ser feita com base nas caracterÃ­sticas dos dados e nos requisitos de desempenho da aplicaÃ§Ã£o. A utilizaÃ§Ã£o do padrÃ£o **Strategy** e a anÃ¡lise com **OpenTelemetry** permitiram uma visÃ£o mais profunda dos desempenhos dos algoritmos, auxiliando na escolha do mais adequado para diferentes cenÃ¡rios.

